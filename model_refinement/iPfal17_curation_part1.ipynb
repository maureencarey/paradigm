{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cobra\n",
    "import os\n",
    "from cobra import Model, Reaction, Metabolite\n",
    "import pandas as pd\n",
    "\n",
    "path = \"/Users/maureencarey/local_documents/work/comparative_parasite_models/paradigm\"\n",
    "data_path = \"/Users/maureencarey/local_documents/work/comparative_parasite_models/paradigm/data\"\n",
    "os.chdir(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf_model = cobra.io.read_sbml_model(\"./other_models/iPfal17.xml\")\n",
    "\n",
    "# update gene identifiers\n",
    "aliases = pd.read_csv('Pfalciparum3D7_GeneAliases.csv')\n",
    "rename_dictionary1 = dict()\n",
    "for index, row in aliases.iterrows():\n",
    "    for x in ['name2','name3','name4','Unnamed: 4','Unnamed: 5','Unnamed: 6','Unnamed: 7']:\n",
    "        if row[x] != 'nan':\n",
    "            rename_dictionary1[row[x]] = row['name1']\n",
    "    \n",
    "rename_dictionary = dict()\n",
    "for key, value in rename_dictionary1.items():\n",
    "    if isinstance(key, str):\n",
    "        if key in [x.id for x in pf_model.genes]:\n",
    "            rename_dictionary[key] = value\n",
    "        elif key.startswith('MAL'):\n",
    "            s = key.replace('.','_')\n",
    "            if s in [x.id for x in pf_model.genes]:\n",
    "                rename_dictionary[s] = value\n",
    "                \n",
    "for key, value in rename_dictionary.items():\n",
    "    if '.' in value:\n",
    "        rename_dictionary[key] = value.split('.')[0]\n",
    "\n",
    "def rename_genes_updated(cobra_model, rename_dict):\n",
    "\n",
    "    from six import iteritems\n",
    "    from ast import NodeTransformer\n",
    "    from cobra.core import Gene, Metabolite, Reaction\n",
    "    from cobra.core.gene import ast2str\n",
    "    from cobra.manipulation.delete import get_compiled_gene_reaction_rules\n",
    "\n",
    "    recompute_reactions = set()  # need to recomptue related genes\n",
    "    remove_genes = []\n",
    "    for old_name, new_name in iteritems(rename_dict):\n",
    "        # undefined if there a value matches a different key\n",
    "        # because dict is unordered\n",
    "        try:\n",
    "            gene_index = cobra_model.genes.index(old_name)\n",
    "        except ValueError:\n",
    "            gene_index = None\n",
    "        old_gene_present = gene_index is not None\n",
    "        new_gene_present = new_name in cobra_model.genes\n",
    "        if old_gene_present and new_gene_present:\n",
    "            old_gene = cobra_model.genes.get_by_id(old_name)\n",
    "            if old_gene != cobra_model.genes.get_by_id(new_name): # Added in case not renaming some\n",
    "                remove_genes.append(old_gene)\n",
    "                recompute_reactions.update(old_gene._reaction)\n",
    "        elif old_gene_present and not new_gene_present:\n",
    "            # rename old gene to new gene\n",
    "    #         old_gene = cobra_model.genes.get_by_id(old_name) #added\n",
    "            gene = cobra_model.genes[gene_index]\n",
    "            # trick DictList into updating index\n",
    "            cobra_model.genes._dict.pop(gene.id)  # ugh\n",
    "            gene.id = new_name\n",
    "            cobra_model.genes[gene_index] = gene\n",
    "    #         recompute_reactions.update(old_gene._reaction) # ADDED\n",
    "        elif not old_gene_present and new_gene_present:\n",
    "            pass # already fixed\n",
    "        else:  # not old gene_present and not new_gene_present\n",
    "            # the new gene's _model will be set by repair\n",
    "            # cobra_model.genes.append(Gene(new_name)) # Removed, otherwise, adds genes that are unassigned to reactions\n",
    "            pass\n",
    "\n",
    "    cobra_model.repair()\n",
    "\n",
    "    class Renamer(NodeTransformer):\n",
    "        def visit_Name(self, node):\n",
    "            node.id = rename_dict.get(node.id, node.id)\n",
    "            return node\n",
    "\n",
    "    gene_renamer = Renamer()\n",
    "    for rxn, rule in iteritems(get_compiled_gene_reaction_rules(cobra_model)):\n",
    "        if rule is not None:\n",
    "            rxn._gene_reaction_rule = ast2str(gene_renamer.visit(rule))\n",
    "\n",
    "    for rxn in recompute_reactions:\n",
    "        rxn.gene_reaction_rule = rxn._gene_reaction_rule\n",
    "    for i in remove_genes:\n",
    "        cobra_model.genes.remove(i)\n",
    "    \n",
    "rename_genes_updated(pf_model,rename_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <table>\n",
       "            <tr>\n",
       "                <td><strong>Reaction identifier</strong></td><td>SK_heme_degraded_fv</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Name</strong></td><td>degraded heme sink</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Memory address</strong></td>\n",
       "                <td>0x011242e160</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Stoichiometry</strong></td>\n",
       "                <td>\n",
       "                    <p style='text-align:right'>heme_degraded_fv <=> </p>\n",
       "                    <p style='text-align:right'>degraded heme <=> </p>\n",
       "                </td>\n",
       "            </tr><tr>\n",
       "                <td><strong>GPR</strong></td><td></td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Lower bound</strong></td><td>-1000.0</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Upper bound</strong></td><td>1000.0</td>\n",
       "            </tr>\n",
       "        </table>\n",
       "        "
      ],
      "text/plain": [
       "<Reaction SK_heme_degraded_fv at 0x11242e160>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ana's curation for glutathione\n",
    "pf_model.reactions.get_by_id('HMGLB').add_metabolites({pf_model.metabolites.get_by_id('h2o2_c'):1.,\n",
    "                         pf_model.metabolites.get_by_id('h_c'):-2.})\n",
    "pf_model.reactions.get_by_id('HMGLB').notes['References'] = 'doi: 10.1073/pnas.0601876103; DOI: 10.1111/j.1365-2141.1975.tb00540.x'\n",
    "\n",
    "pheme_c = pf_model.metabolites.get_by_id('pheme_c')\n",
    "gthrd_c = pf_model.metabolites.get_by_id('gthrd_c')\n",
    "gthox_c = pf_model.metabolites.get_by_id('gthox_c')\n",
    "pheme_fv = pf_model.metabolites.get_by_id('pheme_fv')\n",
    "h2o2_c = pf_model.metabolites.get_by_id('h2o2_c')\n",
    "heme_degraded_c = Metabolite('heme_degraded_c', formula='',\n",
    "    name='degraded heme', compartment='c')\n",
    "heme_degraded_fv = Metabolite('heme_degraded_fv',formula='',\n",
    "    name='degraded heme',compartment='fv')\n",
    "\n",
    "new_rxn = Reaction()\n",
    "new_rxn.name = 'gthrd_heme'\n",
    "new_rxn.id = 'gthrd_heme'\n",
    "new_rxn.add_metabolites({pheme_c : -1,gthrd_c : -1,\n",
    "    gthox_c : +1,    heme_degraded_c : +1 })\n",
    "new_rxn.lower_bound = 0.\n",
    "new_rxn.upper_bound = 1000.\n",
    "new_rxn.notes['References'] = 'doi: 10.1074/jbc.270.42.24876'\n",
    "pf_model.add_reactions([new_rxn])\n",
    "\n",
    "new_rxn = Reaction()\n",
    "new_rxn.name = 'perox_heme'\n",
    "new_rxn.id = 'perox_heme'\n",
    "new_rxn.add_metabolites({pheme_fv : -1, h2o2_c : -1, heme_degraded_fv : +1 })\n",
    "new_rxn.lower_bound = 0.\n",
    "new_rxn.upper_bound = 1000.\n",
    "new_rxn.notes['References'] = 'doi: 10.1042/bj1740893'\n",
    "pf_model.add_reactions([new_rxn])\n",
    "\n",
    "pf_model.add_boundary(heme_degraded_c, type=\"sink\", reaction_id=\"SK_heme_degraded_c\",lb=0, ub=1000.0)\n",
    "pf_model.add_boundary(heme_degraded_fv, type=\"sink\", reaction_id=\"SK_heme_degraded_fv\",\n",
    "                     lb=0, ub=1000.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make dictionary to make all metabolite IDs compatible with bigg\n",
    "# IN FUTURE, EXPAND TO ALL MODELS # for model in [pf_curated, chominis, leish]:\n",
    "universal_model = cobra.io.load_json_model('universal_model_may2018.json')\n",
    "\n",
    "d_list = list()\n",
    "for met in pf_model.metabolites:\n",
    "    if met.id.endswith('_ap'):\n",
    "        num = -3\n",
    "    else:\n",
    "        num = -2\n",
    "    if '_D_' in met.id:\n",
    "        x = met.id[:num].replace('_D_','__D_')\n",
    "        d_list.append(met.id)\n",
    "    else:\n",
    "        x = met.id[:num]\n",
    "    if x not in [y.id[:-2] for y in universal_model.metabolites]:\n",
    "        yasdfas = True # filler\n",
    "        # # print(\"'\"+met.id+\"'\"+\":\"+\"'',\") ## COPY AND PASTE THIS TO NEXT SECTION\n",
    "\n",
    "# switch _D_ to __D_ to be BiGG compatible\n",
    "for met in [x for x in d_list if '__' not in x]:\n",
    "    pf_model.metabolites.get_by_id(met).name = pf_model.metabolites.get_by_id(met).name.replace('_D','__D')\n",
    "    pf_model.metabolites.get_by_id(met).id = pf_model.metabolites.get_by_id(met).id.replace('_D_','__D_')\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "met_dict = {'3oodcoa_c':'3ohodcoa_c', \n",
    "#'5mti_c':'',\n",
    "'5mtr1p_c':'5mtr1p_c', # new met\n",
    "'Asn_X_Ser_FSLASH_Thr_c':'Asn_X_Ser_Thr_c',\n",
    "'acgpail_c':'acgpail_c', # consistent, i.e. acgpail_hs\n",
    "'cdpdag_c':'cdpdag_c', # consistent, species specific IDs\n",
    "'cdpdag_e':'cdpdag_e', # consistent, species specific IDs\n",
    "'crm_c':'crm_c', # consistent i.e. crm_hs\n",
    "'dag_c':'dag_c', # consistent i.e. dag_hs\n",
    "'dag_e':'dag_e', # consistent i.e. dag_hs\n",
    "'dhcrm_c':'dhcrm_c', # consistent i.e. dhcrm_hs\n",
    "'doldp_L_c':'doldp_c',\n",
    "'dolmanp_L_c':'dolmanp_c',\n",
    "'g3m8mpdol_L_c':'g3m8mpdol_c',\n",
    "'gacpail_c':'gacpail_c', # consistent i.e. gacpail_cho\n",
    "'glc__D_e_c':'glc__D_c', # CHECK THAT ITS C\n",
    "'gluside_c':'gluside_c', # consistent i.e. gluside_hs\n",
    "'gpail_c':'gpail_c', # consistent i.e. gpail_hs\n",
    "'hb_c':'hb_c', # hemoglobin, new metabolite\n",
    "'hb_e':'hb_e', # hemoglobin, new metabolite\n",
    "'hcys_L_c':'hcys__L_c',\n",
    "'lgt_S_c':'lgt__S_c',\n",
    "'lpchol_c':'lpchol_c', # consistent i.e. lpchol_hs\n",
    "'m5mpdol_L_c':'m5mpdol_c', \n",
    "'m6mpdol_L_c':'m6mpdol_c',\n",
    "'m7mpdol_L_c':'m7mpdol_c',\n",
    "'pail_c':'pail_c', # consistent i.e. pail_hs\n",
    "'pc_c':'pc_c', # 'host' pc (aggregate)\n",
    "'pc_e':'pc_e', # 'host' pc (aggregate)\n",
    "'pe_c':'pe_c', # 'host' pe (aggregate)\n",
    "'pe_e':'pe_e', # 'host' pe (aggregate)\n",
    "'ptd145bp_c':'ptd145bp_c', # consistent, species specific IDs\n",
    "'ptd1ino_c':'ptd1ino_c', # consistent, species specific IDs\n",
    "'ptd1ino_e':'ptd1ino_e', # consistent, species specific IDs\n",
    "'ptd3ino_c':'ptd3ino_c', # consistent, species specific IDs\n",
    "'ptd4ino_c':'ptd4ino_c', # consistent, species specific IDs\n",
    "'saccrp_L_c':'saccrp__L_c',\n",
    "'sertrna_sec__c':'sertrna_sec_c',\n",
    "'sphmyln_c':'sphmyln_c', # consistent i.e. sphmyln_hs\n",
    "'tag_c':'tag_c', # AGGREGATE\n",
    "'up4u_c':'up4u_c', #new metabolite\n",
    "'xolest2_c':'xolest2_c', # consistent, i.e. xolest2_hs\n",
    "'xolest2_e':'xolest2_e', # consistent, i.e. xolest2_hs\n",
    "'pail_e':'pail_e', # consistent i.e. pail_hs\n",
    "'Asn_X_Ser_FSLASH_Thr_e':'Asn_X_Ser_Thr_e',\n",
    "'naglc2p_L_c':'naglc2p__L_c',\n",
    "'m4mpdol_L_c':'m4mpdol__L_c',\n",
    "'m8mpdol_L_c':'m8mpdol__L_c',\n",
    "'hemeA_fv':'hemeA_fv', # new compartment\n",
    "#'psertrna_sec_c':'',\n",
    "#'pnte_c':'',\n",
    "#'2aeth_c':'',\n",
    "'hemozoin_fv':'hemozoin_fv', # new met and compartment\n",
    "'hemozoin_e':'hemozoin_e', # new met \n",
    "# 'pyrdat_c':'',\n",
    "'gluside_e':'gluside_e', # consistent i.e. gluside_hs\n",
    "'mgacpail_c':'mgacpail_c', # consistent i.e. mgacpail_hs\n",
    "'sphmyln_e':'sphmyln_e', # consistent i.e.sphmln_hs\n",
    "'ROOH_ap':'ROOH_ap', # aggregate\n",
    "'ROH_ap':'ROH_ap', # aggregate\n",
    "'protein_t_c':'protein_t_c', # host specific\n",
    "'gthox_protein_c':'gthox_protein_c', # host specific\n",
    "'gthox_protein_e':'gthox_protein_e', # host specific\n",
    "'protein_t_e':'protein_t_e', # host specific\n",
    "'ROOH_c':'ROOH_c', # aggregate\n",
    "'ROH_c':'ROH_c', # aggregate\n",
    "'ROOH_m':'ROOH_m', # aggregate\n",
    "'ROH_m':'ROH_m', # aggregate\n",
    "'proteinSS_c':'protdt_c',\n",
    "'proteinSHSH_c':'protds_c',\n",
    "'proteinSS_ap':'protdt_ap',\n",
    "'proteinSHSH_ap':'protds_ap',\n",
    "'proteinSS_m':'protdt_m',\n",
    "'proteinSHSH_m':'protds_m',\n",
    "'all_pc_c':'all_pc_c', # AGGREGATE\n",
    "'all_pe_c':'all_pe_c', # AGGREGATE\n",
    "'all_ps_c':'all_ps_c', # AGGREGATE\n",
    "'all_pi_c':'all_pi_c', # AGGREGATE\n",
    "'all_pg_c':'all_pg_c', # AGGREGATE\n",
    "'all_apg_c':'all_apg_c', # AGGREGATE\n",
    "'all_dgl_c':'all_dgl_c', # AGGREGATE\n",
    "'lipid_c':'lipid_c'} # AGGREGATE\n",
    "\n",
    "for x in pf_model.metabolites:\n",
    "    if x.id in met_dict.keys():\n",
    "        if x.id != met_dict[x.id]:\n",
    "            x.id = met_dict[x.id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1196\n",
      "1195\n",
      "1196\n"
     ]
    }
   ],
   "source": [
    "# THINGS TO CURATE\n",
    "print(len(pf_model.reactions))\n",
    "pf_model.reactions.get_by_id('hcys_ex').remove_from_model() # duplicate with EX_hcys___L_e\n",
    "print(len(pf_model.reactions))\n",
    "pf_model.add_boundary(pf_model.metabolites.get_by_id('protein_t_e'), type=\"exchange\")\n",
    "print(len(pf_model.reactions))\n",
    "\n",
    "# [x.reaction for x in pf_curated.metabolites.get_by_id('protein_t_e').reactions]\n",
    "# # pf_curated.reactions.PUNP8 # CURATED SOMETHING WRONG\n",
    "# pf_curated.reactions.UP4UH1\n",
    "# # pf_curated.reactions.get_by_id('PYRDAT') # SOMETHING WRONG, genes don't make sense\n",
    "# # not bigg canocnical rxns PNTK2, PNTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp_dict = dict() # get products and reactants for every reaction\n",
    "# for rxn in universal_model.reactions:\n",
    "#     rxn_dict = dict()\n",
    "#     check_rxn_products = rxn.products\n",
    "#     check_rxn_reactants = rxn.reactants\n",
    "#     rxn_dict['reactants'] = [x.id for x in check_rxn_reactants]\n",
    "#     rxn_dict['products'] = [x.id for x in check_rxn_products]\n",
    "#     temp_dict[rxn.id] = rxn_dict\n",
    "\n",
    "# # list duplicate reactions\n",
    "# l = list() # list of duplicate reactions, bounds might be different\n",
    "# for key, value in temp_dict.items():\n",
    "#     temp_dict2 = temp_dict.copy()\n",
    "#     del temp_dict2[key]\n",
    "#     if value in [value2 for value2 in temp_dict2.values()]:\n",
    "#         l.append(key)\n",
    "\n",
    "# # map duplicate reactions to each other\n",
    "# for x in l: \n",
    "#     if x in skip_these:\n",
    "#         continue\n",
    "#     else:\n",
    "#         reactants_products = temp_dict[x] \n",
    "#         usable_l = list(set(l) - set(skip_these) - set([x]))\n",
    "#         all_other_rxns_reactants_products = [temp_dict[y] for y in usable_l]\n",
    "#         if reactants_products in all_other_rxns_reactants_products:\n",
    "#             del temp_dict[x]\n",
    "#             keys_to_delete = list()\n",
    "#             for key in temp_dict.keys():\n",
    "#                 if temp_dict[key]['products'] == reactants_products['products'] and \\\n",
    "#                 temp_dict[key]['reactants'] == reactants_products['reactants']:\n",
    "#                     keys_to_delete.append(key)\n",
    "#             for keys_delete in keys_to_delete:\n",
    "#                 del temp_dict[keys_delete]\n",
    "#                 skip_these.append(keys_delete)\n",
    "#             duplicates2[x] = keys_to_delete\n",
    "#     skip_these.append(x)\n",
    "    \n",
    "# # print\n",
    "# for key, value in duplicates2.items():\n",
    "#     print(key)\n",
    "#     print(universal_model.reactions.get_by_id(key).reaction)\n",
    "#     print(universal_model.reactions.get_by_id(key).bounds)\n",
    "    \n",
    "#     print(value)\n",
    "#     for x in value:\n",
    "#         print(universal_model.reactions.get_by_id(x).reaction)\n",
    "#         print(universal_model.reactions.get_by_id(x).bounds)\n",
    "#     print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# similarity_exceptions = duplicates2\n",
    "import json\n",
    "# class JSONEncoder(json.JSONEncoder):\n",
    "#     def default(self, obj):\n",
    "#         if hasattr(obj, 'to_json'):\n",
    "#             return obj.to_json(orient='records')\n",
    "#         return json.JSONEncoder.default(self, obj)\n",
    "# with open('similarity_exceptions_july23.json', 'w') as fp:\n",
    "#     json.dump(similarity_exceptions, fp, cls=JSONEncoder)\n",
    "#     # THESE ARE REACTIONS WITH DIFFERENT IDS BUT HAVE SIMILAR/SAME FUNCTION\n",
    "\n",
    "similarity_exceptions = json.load(open('/Users/maureencarey/local_documents/work/comparative_parasite_models/paradigm/similarity_exceptions_july23.json'))\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temp dict made\n",
      "[]\n",
      "duplicates made\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# FIND/ REMOVE DUPLICATE REACTIONS\n",
    "\n",
    "duplicates = dict()\n",
    "temp_dict = dict() # get products and reactants for every reaction\n",
    "for rxn in pf_model.reactions:\n",
    "    rxn_dict = dict()\n",
    "    check_rxn_products = rxn.products\n",
    "    check_rxn_reactants = rxn.reactants\n",
    "    rxn_dict['reactants'] = [x.id for x in check_rxn_reactants]\n",
    "    rxn_dict['products'] = [x.id for x in check_rxn_products]\n",
    "    temp_dict[rxn.id] = rxn_dict\n",
    "\n",
    "print('temp dict made')\n",
    "print([key for key in temp_dict.keys() if key not in [x.id for x in pf_model.reactions]])\n",
    "\n",
    "for rxn in universal_model.reactions:\n",
    "    for key in temp_dict.keys():\n",
    "        if key != rxn.id:\n",
    "            if [x.id for x in rxn.reactants] == temp_dict[key]['reactants'] and \\\n",
    "            [x.id for x in rxn.products] == temp_dict[key]['products']:\n",
    "                if rxn.id not in duplicates.keys():\n",
    "                    duplicates[rxn.id] = key\n",
    "                elif duplicates[rxn.id] == key or key in duplicates[rxn.id]:\n",
    "                    continue\n",
    "                else:\n",
    "                     duplicates[rxn.id] = duplicates[rxn.id]+', '+key\n",
    "                        \n",
    "print('duplicates made')\n",
    "print([value for value in duplicates.values() if value not in [x.id for x in pf_model.reactions]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCOAL\n",
      "conflicts with reaction in model:\n",
      "ac_c + atp_c + coa_c --> accoa_c + adp_c + pi_c\n",
      "but we wanted to use that id for:\n",
      "ACCOAL2\n",
      "atp_c + coa_c + ppa_c --> adp_c + pi_c + ppcoa_c\n"
     ]
    }
   ],
   "source": [
    "# #  replace pf reaction ids with BiGG id for same reaction string\n",
    "# # NOTE: some have different reaction bounds. see:\n",
    "# for key, value in duplicates.items():\n",
    "#     print(value)\n",
    "#     print(pf_curated.reactions.get_by_id(value).reaction)\n",
    "#     print(pf_curated.reactions.get_by_id(value).bounds)\n",
    "#     print(key)\n",
    "#     print(universal_model.reactions.get_by_id(key).reaction)\n",
    "#     print(universal_model.reactions.get_by_id(key).bounds)\n",
    "#     print(' ')\n",
    "\n",
    "for key, value in duplicates.items():\n",
    "    # key is universal id\n",
    "    # value is pf id\n",
    "    if key in ['SUCCt2r','MALt2r','FUMt2r','ASPt2r'] or value in ['SUCCt2r','MALt2r','FUMt2r','ASPt2r']:\n",
    "        continue\n",
    "    elif (key in similarity_exceptions.keys() or key in similarity_exceptions.values()) and \\\n",
    "    (value in similarity_exceptions.keys() or key in similarity_exceptions.values()):\n",
    "        continue # continue to next key value pair\n",
    "    elif key in [x.id for x in pf_model.reactions]:\n",
    "#         print('replacement string')\n",
    "        print(key)\n",
    "        print('conflicts with reaction in model:')\n",
    "        print(pf_model.reactions.get_by_id(key).reaction)\n",
    "        print('but we wanted to use that id for:')\n",
    "        print(value)\n",
    "        print(pf_model.reactions.get_by_id(value).reaction)\n",
    "    else:\n",
    "        if value in [x.id for x in pf_model.reactions]:\n",
    "            pf_model.reactions.get_by_id(value).id = key # now BiGG compatible\n",
    "        \n",
    "pf_model.reactions.get_by_id('ATPtm').id = 'ATPPHm'\n",
    "# pf_model.reactions.get_by_id('ATPADPexm').id = 'ATPtm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(data_path+'/other_models')\n",
    "cobra.io.write_sbml_model(pf_model, \"iPfal18_pregapfilling.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29.866835591947282"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pf_model.slim_optimize()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
