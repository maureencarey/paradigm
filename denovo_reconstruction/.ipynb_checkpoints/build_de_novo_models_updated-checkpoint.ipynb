{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cobra\n",
    "import pandas as pd\n",
    "import os\n",
    "import subprocess\n",
    "import glob\n",
    "import json\n",
    "from cobra import Model, Reaction, Metabolite\n",
    "path = \"/Users/maureencarey/local_documents/work/comparative_parasite_models/paradigm\"\n",
    "data_path = \"/Users/maureencarey/local_documents/work/comparative_parasite_models/paradigm/data\"\n",
    "\n",
    "# load curated Plasmodium falciparum model # THIS ONE ISN\"T CURATED THOUGH need iPfal18\n",
    "os.chdir(data_path+'/other_models')\n",
    "# iPfal17 = cobra.io.read_sbml_model(\"iPfal17.xml\")\n",
    "\n",
    "# load universal model\n",
    "os.chdir(data_path)\n",
    "universal_model = cobra.io.load_json_model('universal_model_may2018.json')\n",
    "  \n",
    "# open/add exchanges and remove unnecessary biomass functions from universal\n",
    "for rxn in universal_model.reactions:\n",
    "    if rxn.id.startswith('EX_'):\n",
    "        rxn.lower_bound = -1000.\n",
    "        rxn.upper_bound = 1000.\n",
    "for met in universal_model.metabolites:\n",
    "    if met.id.endswith('_e'):\n",
    "        if 'EX_'+met.id not in universal_model.reactions:\n",
    "            universal_model.add_boundary(met, type = 'exchange')\n",
    "for rxn in [r for r in universal_model.reactions if r.id.lower().startswith('biomass')]:\n",
    "    rxn.remove_from_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generic things - use for all species\n",
    "\n",
    "# get available compartments\n",
    "compartment_options = list()\n",
    "for string in [met.id for met in universal_model.metabolites]:\n",
    "    if string.startswith('EX_') or string.startswith('DM_') or string.startswith('SK_'):\n",
    "        s = 'asedf'\n",
    "    else:\n",
    "        compartment_options.append('_'+string.split('_')[len(string.split('_'))-1])\n",
    "compartment_options = set(compartment_options)\n",
    "\n",
    "# get metabolites involved in reactions in universal model in dictionary format\n",
    "universal_dict = dict() # get products and reactants for every reaction\n",
    "for rxn in universal_model.reactions:\n",
    "    rxn_dict = dict()\n",
    "    \n",
    "    check_rxn_products = rxn.products\n",
    "    check_rxn_reactants = rxn.reactants\n",
    "    all_mets = rxn.metabolites\n",
    "    compart = set([x.id[-2:] for x in all_mets])\n",
    "    \n",
    "    rxn_dict['reactants'] = [x.id[:-2] for x in check_rxn_reactants]\n",
    "    rxn_dict['products'] = [x.id[:-2] for x in check_rxn_products]\n",
    "    rxn_dict['compartment'] = list(compart)\n",
    "    \n",
    "    universal_dict[rxn.id] = rxn_dict\n",
    "# universal_dict = all universal model reactions, mapped to a dictionary \n",
    "# containing its compartment, products and reactants\n",
    "\n",
    "# map reactions to duplicate reactions in different compartments\n",
    "universal_dict_with_alts = universal_dict.copy() \n",
    "for reaction, data in universal_dict_with_alts.items():\n",
    "    alternative_reactions = dict()\n",
    "    data_with_options = data.copy()\n",
    "    for potential_rxn,potential_data in universal_dict.items():\n",
    "        if potential_rxn != reaction:\n",
    "            if potential_data['reactants'] == data['reactants'] and \\\n",
    "            potential_data['products'] == data['products']:\n",
    "                alternative_reactions[potential_rxn] = potential_data['compartment']\n",
    "        \n",
    "    data_with_options['alternative_reactions'] = alternative_reactions\n",
    "    universal_dict_with_alts[reaction] = data_with_options\n",
    "    \n",
    "# database mapping # MUST UPDATE\n",
    "plasmodb = [\"PadleriG01\",\"PbergheiANKA\",\"PbillcollinsiG01\",\"PblacklockiG01\",\"Pchabaudichabaudi\",\"PcoatneyiHackeri\",\"PcynomolgiB\",\"PcynomolgiM\",\"Pfalciparum3D7\",\"PfalciparumIT\",\"PfragileNilgiri\",\"PgaboniG01\",\"PgaboniSY75\",\"Pgallinaceum8A\",\"PinuiSanAntonio1\",\"PknowlesiH\",\"PknowlesiMalayanPk1A\",\"PmalariaeUG01\",\"PovalecurtisiGH01\",\"PpraefalciparumG01\",\"PreichenowiCDC\",\"PreichenowiG01\",\"PrelictumSGS1-like\",\"PvinckeipetteriCR\",\"Pvinckeivinckeivinckei\",\"PvivaxP01\",\"PvivaxSal1\",\"Pyoeliiyoelii17X\",\"Pyoeliiyoelii17XNL\",\"PyoeliiyoeliiYM\"]\n",
    "# MUST ASK PERMISSION TO USE 3D7\n",
    "cryptodb = [\"Candersoni30847\",\"Chominis30976\",\"ChominisTU502\",\"ChominisTU502_2012\",\"ChominisUdeA01\",\"CmeleagridisUKMEL1\",\"CmurisRN66\",\"CparvumIowaII\",\"CtyzzeriUGA55\", \"Cubiquitum39726\",\"CveliaCCMP2878\", \"GniphandrodesUnknown\", \"VbrassicaformisCCMP3155\"]\n",
    "giardiadb = [\"GintestinalisAssemblageADH\", \"GintestinalisAssemblageAWB\", \"GintestinalisAssemblageBGS\", \"GintestinalisAssemblageBGS_B\", \"GintestinalisAssemblageEP15\", \"SsalmonicidaATCC50377\"]\n",
    "tritrypdb = [\"BayalaiB08-376\",\"CfasciculataCfCl\",\"EmonterogeiiLV88\",\"LaethiopicaL147\", \"LarabicaLEM1108\", \"LbraziliensisMHOMBR75M2903\", \"LbraziliensisMHOMBR75M2904\", \"LdonovaniBPK282A1\", \"LenriettiiLEM3045\", \"LgerbilliLEM452\",\"LinfantumJPCM5\", \"LmajorFriedlin\", \"LmajorLV39c5\", \"LmajorSD75.1\", \"LmexicanaMHOMGT2001U1103\", \"LpanamensisMHOMCOL81L13\",\"LpanamensisMHOMPA94PSC1\", \"LpyrrhocorisH10\", \"LseymouriATCC30220\", \"LspMARLEM2494\", \"LtarentolaeParrotTarII\", \"LtropicaL590\", \"LturanicaLEM423\", \"PconfusumCUL13\",\"TbruceigambienseDAL972\", \"TbruceiLister427\", \"TbruceiTREU927\", \"TcongolenseIL3000\", \"TcruziCLBrener\", \"TcruziCLBrenerEsmeraldo-like\", \"TcruziCLBrenerNon-Esmeraldo-like\", \"TcruzicruziDm28c\",\"TcruziDm28c\", \"TcruzimarinkelleiB7\", \"TcruziSylvioX10-1\", \"TcruziSylvioX10-1-2012\",\"TevansiSTIB805\", \"TgrayiANR4\", \"TrangeliSC58\", \"TvivaxY486\", \"TtheileriEdinburgh\"]\n",
    "# MUST ASK PERMISSION TO USE MANY OF THE TRITRYP GENOMES - S.M. Beverley at Wash U\n",
    "trichdb = [\"TvaginalisG3\"]\n",
    "amoebadb = [\"AcastellaniiNeff\", \"EdisparSAW760\", \"EhistolyticaHM1IMSS-A\", \"EhistolyticaHM1IMSS-B\", \"EhistolyticaHM1IMSS\", \"EhistolyticaHM3IMSS\", \"EhistolyticaKU27\", \"EinvadensIP1\", \"EmoshkovskiiLaredo\", \"EnuttalliP19\", \"NfowleriATCC30863\"]\n",
    "toxodb = [\"CcayetanensisCHN_HEN01\", \"CsuisWienI\",\"EacervulinaHoughton\", \"EbrunettiHoughton\", \"EfalciformisBayerHaberkorn1970\", \"EmaximaWeybridge\", \"EmitisHoughton\", \"EnecatrixHoughton\", \"EpraecoxHoughton\", \"EtenellaHoughton\", \"HhammondiHH34\", \"NcaninumLIV\", \"SneuronaSN3\", \"SneuronaSOSN1\", \"TgondiiARI\", \"TgondiiFOU\", \"TgondiiGAB2-2007-GAL-DOM2\", \"TgondiiGT1\", \"TgondiiMAS\", \"TgondiiME49\", \"Tgondiip89\", \"TgondiiRH\", \"TgondiiRUB\", \"TgondiiTgCatPRC2\", \"TgondiiVAND\", \"TgondiiVEG\"]\n",
    "microsporidiadb = [\"AalgeraePRA109\", \"AalgeraePRA339\", \"EaedisUSNM41457\", \"EbieneusiH348\", \"EcanceriGB1\",\"EcuniculiEC1\", \"EcuniculiEC2\", \"EcuniculiEC3\", \"EcuniculiGBM1\", \"EhellemATCC50504\", \"EhellemSwiss\", \"EhepatopenaeiTH1\",\"EintestinalisATCC50506\",\"EromaleaeSJ2008\",\"Heriocheircanceri\",\"HeriocheirGB1\", \"MdaphniaeUGP3\", \"NausubeliERTm2\", \"NausubeliERTm6\", \"NbombycisCQ1\", \"NceranaeBRL01\", \"NdisplodereJUm2807\",\"NparisiiERTm1\", \"NparisiiERTm3\", \"OcolligataOC4\", \"PneurophiliaMK1\", \"Slophii42_110\", \"ThominisUnknown\", \"VcorneaeATCC50505\", \"Vculicisfloridensis\"]\n",
    "piroplasmadb = [\"BbigeminaBOND\", \"BbovisT2Bo\", \"BmicrotiRI\",\"BovataMiyake\", \"CfelisWinnie\", \"TannulataAnkara\", \"TequiWA\", \"TorientalisShintoku\", \"TparvaMuguga\"]\n",
    "fungidb = [\"AaculeatusATCC16872\", \"AbrasiliensisCBS101740\", \"AcampestrisIBT28561\", \"Acandida2VRR\", \"AcarbonariusITEM5010\", \"AclavatusNRRL1\", \"AfischeriNRRL181\",\"AflavusNRRL3357\",\"AfumigatusA1163\",\"AfumigatusAf293\", \"AglaucusCBS516.65\",\"AinvadansNJM9701\", \"AlaibachiiNc14\", \"AluchuensisCBS106.47\", \"AmacrogynusATCC38327\", \"AnidulansFGSCA4\", \"AnigerATCC1015\", \"AnigerCBS513-88\", \"AnovofumigatusIBT16806\", \"AochraceoroseusIBT24754\",\"AoryzaeRIB40\", \"AsteyniiIBT23096\", \"AsydowiiCBS593.65\", \"AterreusNIH2624\", \"AtubingensisCBS134.48\", \"AversicolorCBS583.65\", \"AwentiiDTO134E9\",\"AzonataCBS506.65\", \"BcinereaB05-10\", \"BdendrobatidisJEL423\", \"CalbicansSC5314\", \"CalbicansSC5314_B\", \"CalbicansWO1\", \"CaurisB8441\", \"Ccinereaokay7-130\", \"CdeuterogattiiR265\", \"CgattiiCA1873\", \"CgattiiEJB2\", \"CgattiiIND107\", \"CgattiiWM276\", \"CglabrataCBS138\", \"CimmitisH538-4\", \"CimmitisRS\", \"ClusitaniaeATCC42720\", \"CneoformansB-3501A\", \"CneoformansH99\", \"CneoformansJEC21\", \"CneoformansKN99\", \"CposadasiiC735deltSOWgp\", \"CposadasiiRMSCC3488\", \"CposadasiiRMSCC3700\", \"CposadasiiSilveira\", \"FfujikuroiIMI58289\", \"FgraminearumPH-1\", \"Foxysporum26406\", \"Foxysporum4287\", \"Foxysporum54006\", \"FoxysporumFo47\", \"Foxysporumrace1\", \"Foxysporumrace4\", \"Fverticillioides7600\", \"HarabidopsidisEmoy2\", \"HcapsulatumG186AR\", \"HcapsulatumG217B\", \"HcapsulatumH143\", \"HcapsulatumH88\", \"HcapsulatumNAm1\", \"McircinelloidesCBS277-49\", \"MglobosaCBS7966\", \"Mlarici-populina98AG31\", \"Moryzae70-15\", \"MoryzaeBR32\", \"NcrassaOR74A\", \"NdiscretaFGSC8579\", \"NtetraspermaFGSC2508\", \"PaphanidermatumDAOMBR444\", \"ParrhenomanesATCC12531\", \"PblakesleeanusNRRL1555\", \"PbrasiliensisPb03\", \"PbrasiliensisPb18\", \"PcapsiciLT1534\", \"PchrysosporiumRP-78\", \"PcinnamomiCBS144-22\", \"PgraminisCRL75-36-700-3\", \"PinfestansT30-4\", \"PirregulareDAOMBR486\", \"PiwayamaiDAOMBR242034\", \"PjiroveciiSE8\", \"PlutziiPb01\", \"PparasiticaINRA-310\", \"PramorumPr-102\", \"PrubensWisconsin54-1255\", \"PsojaeP6497\", \"PultimumBR650\", \"PultimumDAOMBR144\", \"PvexansDAOMBR484\", \"RdelemarRA99-880\", \"ScerevisiaeS288c\", \"SdiclinaVS20\", \"SjaponicusyFS275\", \"Smacrosporak-hell\", \"SoctosporusyFS286\", \"SparasiticaCBS223\", \"Spombe972h\", \"SpunctatusDAOMBR117\", \"SreilianumSRZ2\", \"Sschenckii1099-18\", \"Ssclerotiorum1980UF-70\", \"TmarneffeiATCC18224\", \"TmesentericaDSM1558\", \"TreeseiQM6a\", \"TstipitatusATCC10500\", \"Umaydis521\", \"Ureesii1704\", \"YlipolyticaCLIB122\", \"ZtriticiIPO323\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load annotation data\n",
    "os.chdir(path)\n",
    "annotations_dict = dict()\n",
    "columns = ['query_gene', 'BiGG_gene', 'pident', 'length', 'mismatch', 'gapopen','qstart', 'qend', 'sstart', 'send', 'evalue', 'score']\n",
    "os.chdir(data_path) # CHECK PATH\n",
    "for filename in glob.glob(os.path.join(data_path+'/diamond_output_BiGG', '*_Jul2018_BiGG.tsv')):\n",
    "    annotations_dict[filename.split('/')[len(filename.split('/'))-1]] = pd.read_table(filename, sep = '\\t', names=columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map to Bigg Functions for model generation\n",
    "# can't use carveme without cplex - so copy and paste carveme code \n",
    "# Use CarveMe to generate BiGG GPRs\n",
    "\n",
    "os.chdir(data_path)\n",
    "gprs = pd.read_csv('bigg_gprs.csv') # From CarveMe\n",
    "gprs.reaction = [x[2:] for x in gprs.reaction]\n",
    "gprs = gprs[gprs.reaction.isin([rxn.id for rxn in universal_model.reactions])] # updated from CarveMe\n",
    "\n",
    "def merge_subunits(genes): # From CarveMe\n",
    "    \"\"\" Merge list of protein subunit genes into complex\n",
    "    Args: genes (pandas.Series): list of genes\n",
    "    Returns: str: boolean rule\n",
    "    \"\"\"\n",
    "    genes = genes.dropna()\n",
    "\n",
    "    if len(genes) == 0:\n",
    "        return None\n",
    "    else:\n",
    "        protein = ' and '.join(sorted(genes))\n",
    "        if len(genes) > 1:\n",
    "            return '(' + protein + ')'\n",
    "        else:\n",
    "            return protein\n",
    "        \n",
    "def merge_subunit_scores(scores): # From CarveMe\n",
    "    \"\"\" Merge scores of all genes in a protein complex.\n",
    "    Calculates the mean score among all subunits.\n",
    "    Args: scores: individual gene scores\n",
    "    Returns: float: merged score\n",
    "    \"\"\"\n",
    "    return scores.fillna(0).mean()\n",
    "\n",
    "def merge_proteins(proteins): # From CarveMe\n",
    "    \"\"\" Merge all isozymes that catalyze a given reaction.\n",
    "    Automatically removes all isozymes with missing score.\n",
    "    Args: proteins (pandas.Series): list of proteins\n",
    "    Returns: str: boolean rule\n",
    "    \"\"\"\n",
    "    proteins = set(proteins.dropna())\n",
    "    if not proteins:\n",
    "        return None\n",
    "    gpr_str = ' or '.join(sorted(proteins))\n",
    "    if len(proteins) > 1:\n",
    "        return '(' + gpr_str + ')'\n",
    "    else:\n",
    "        return gpr_str\n",
    "\n",
    "def merge_protein_scores(scores): # From CarveMe\n",
    "    \"\"\" Merge scores of all isozymes that catalyze a given reaction.\n",
    "    Calculates the maximum score among all isozymes.\n",
    "    Args: scores (pandas.Series): protein scores\n",
    "    Returns: float: merged score\n",
    "    \"\"\"\n",
    "    return scores.max(skipna=True)\n",
    "\n",
    "def reaction_scoring(annotation, gprs, spontaneous_score=0.0, debug_output=None): # From CarveMe\n",
    "    \"\"\" Calculate reaction scores using new eggnog output.\n",
    "    Args: annotation (pandas.DataFrame): gene annotation results\n",
    "        gprs (pandas.DataFrame): BiGG GPR rules\n",
    "        spontaneous_score (float): score to give to spontaneous reactions (default: 0.0)\n",
    "    Returns: pandas.DataFrame: reaction scores\n",
    "    \"\"\"\n",
    "\n",
    "    # filter best match for each gene\n",
    "    gene2gene = annotation.sort_values(by='score', ascending=False) \\\n",
    "                          .groupby('BiGG_gene', as_index=False).apply(lambda x: x.iloc[0])\n",
    "    # merge with gpr table\n",
    "    gprs['BiGG_gene'] = gprs.apply(lambda row: '{}.{}'.format(row['model'], row['gene'][2:]), axis=1)\n",
    "    gene_scores = pd.merge(gene2gene, gprs, how='right')\n",
    "    # add default scores for spontaneous genes\n",
    "    spontaneous = {'G_s0001', 'G_S0001', 'G_s_0001', 'G_S_0001', 'G_KPN_SPONT'}\n",
    "    gene_scores.loc[gene_scores.gene.isin(spontaneous), 'score'] = spontaneous_score\n",
    "    gene_scores.loc[gene_scores.gene.isin(spontaneous), 'query_gene'] = 'spontaneous'\n",
    "    # from gene to protein scores\n",
    "    protein_scores = gene_scores.groupby(['protein', 'reaction', 'model'], as_index=False) \\\n",
    "        .agg({'query_gene': merge_subunits, 'score': merge_subunit_scores})\n",
    "    protein_scores.rename(columns={'query_gene': 'GPR'}, inplace=True)\n",
    "    # from protein to reaction scores\n",
    "    reaction_scores = protein_scores.groupby(['reaction'], as_index=False) \\\n",
    "        .agg({'GPR': merge_proteins, 'score': merge_protein_scores}).dropna()\n",
    "    return(reaction_scores)\n",
    "\n",
    "# varying from CarveMe code here:\n",
    "# skip normalization of reactions scores\n",
    "# skip otpimization of high reaction scores because here we are including ALL potential reactions\n",
    "# regardless of whether that makes a functional model\n",
    "\n",
    "scores_dict2 = dict()\n",
    "for species, annotations in annotations_dict.items():\n",
    "    print(species)\n",
    "    if species == 'CsuisWienI_Jul2018_BiGG.tsv':\n",
    "        annotations = annotations_dict[species]\n",
    "        reaction_scores = reaction_scoring(annotations, gprs)\n",
    "        # scores = dict(reaction_scores[['reaction', 'normalized_score']].values)\n",
    "        scores_dict2[species] = reaction_scores #scores\n",
    "        # carveme will maximize positive scores and minimize negative scores while maintaining a functional network\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'CsuisWienI_Jul2018_BiGG.tsv' in annotations_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # save all scores as json\n",
    "# import json\n",
    "# class JSONEncoder(json.JSONEncoder):\n",
    "#     def default(self, obj):\n",
    "#         if hasattr(obj, 'to_json'):\n",
    "#             return obj.to_json(orient='records')\n",
    "#         return json.JSONEncoder.default(self, obj)\n",
    "# with open('scores_dict2_july23.json', 'w') as fp:\n",
    "#     json.dump(scores_dict2, fp, cls=JSONEncoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(data_path)\n",
    "scores_dict2 = dict()\n",
    "for species in annotations_dict.keys():\n",
    "    scores_dict2[species] = pd.read_json(json.load(open(\\\n",
    "    '/Users/maureencarey/local_documents/work/comparative_parasite_models/paradigm/data/scores_dict2_july11.json'))[species])\n",
    "# distribution of scores? use for confidence?????\n",
    "# duplicate reactions just in different compartments are being added - dealing with this farther down\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model_dict = dict()\n",
    "\n",
    "for x in scores_dict2.keys():\n",
    "    \n",
    "    if '_Jul2018_BiGG.tsv' in x: ###### CHECK ALL THIS\n",
    "        species = x.split('_Jul2018_BiGG.tsv')[0]\n",
    "    elif '.tsv' in x:\n",
    "        print('_May20.tsv not in the annotations file string, this might cause problems')\n",
    "        species = x.split('.tsv')[0]\n",
    "    else:\n",
    "        print('_May20.tsv not in the annotations file string, this might cause problems')\n",
    "        species = x\n",
    "        \n",
    "    new_model_dict[species] = universal_model.copy()\n",
    "    print('copied universal')\n",
    "    new_model_dict[species].name = species\n",
    "    new_model_dict[species].id = species\n",
    "    \n",
    "    print(species)\n",
    "    starting = len(new_model_dict[species].reactions)\n",
    "\n",
    "    keep_scores = scores_dict2[x].loc[scores_dict2[x].score>10]\n",
    "    if len(keep_scores.reaction) == len(set(keep_scores.reaction)):\n",
    "\n",
    "        rxns_to_add = dict()\n",
    "        for index, row in keep_scores.iterrows():\n",
    "            rxns_to_add[row['reaction']] = row['GPR']\n",
    "\n",
    "        new_model_dict[species].remove_reactions([rxn for rxn in new_model_dict[species].reactions if rxn.id not in rxns_to_add.keys()])\n",
    "        \n",
    "        if not [rxn.id for rxn in new_model_dict[species].reactions if rxn.gene_reaction_rule != '']:\n",
    "            for rxn in new_model_dict[species].reactions:\n",
    "                    if rxn.gene_reaction_rule == '':\n",
    "                        rxn.gene_reaction_rule = rxns_to_add[rxn.id]\n",
    "        else:\n",
    "            print('some reactions already have GPRs')\n",
    "\n",
    "        print('made new model from universal')\n",
    "        new_model_dict[species].repair()\n",
    "\n",
    "        if len(rxns_to_add.keys()) == len(new_model_dict[species].reactions):\n",
    "            if starting > len(rxns_to_add.keys()):\n",
    "                print(' ')\n",
    "            else:\n",
    "                print('error with original model, reactions already removed')\n",
    "        else:\n",
    "            print('error with reaction removal, resultant len(model.reactions) != rxns_to_keep')\n",
    "    else:\n",
    "        print('duplicate keep_scores.reaction')\n",
    "        \n",
    "    if len(rxns_to_add.keys()) != len(new_model_dict[species].reactions):\n",
    "        print('error in universal reaction pruning')\n",
    "    #cobra.io.save_json_model(new_model_dict[species], \"DIY1_\"+species+\".json\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove duplicate reactions in mulitple compartments\n",
    "total_compartments = [\"_c\",\"_e\",\"_m\",\"_ap\",\"_fv\",\"_k\",\"_glc\",\"_pm\"]\n",
    "# cytosol, extracellular, mitochondrdia, apicoplast, food vacuole, kinetoplast, glycosome, pseudomitochondria\n",
    "\n",
    "compartment_dictionary = dict()\n",
    "for species in new_model_dict.keys():\n",
    "    \n",
    "    # Plasmodium = cytosol, extracellular, mitochondrdia, apicoplast, food vacuole\n",
    "    if species in plasmodb:\n",
    "    # if species.startswith('P') and species is not 'PneurophiliaMK1' and species is not 'PconfusumCUL13':\n",
    "        # PneurophiliaMK1_May20 is microsporidia\n",
    "        # PconfusumCUL13_May20 trypanosoma\n",
    "        model_compartments = [\"_c\",\"_e\",\"_m\",\"_ap\",\"_fv\"]\n",
    "            \n",
    "    # Leishmania = cytosol, extracellular, mitochondrdia, kinetoplast, glycosome\n",
    "    elif species in tritrypdb:\n",
    "    # elif species.startswith('L') and species is not \"LpyrrhocorisH10\":\n",
    "        #LpyrrhocorisH10_May20.tsv is Leptomonas\n",
    "        model_compartments = [\"_c\",\"_e\",\"_m\",\"_k\",\"_glc\"]\n",
    "    \n",
    "    # Cryptosporidium = cytosol, extracellular, pseudomitochondria (USE MITO)\n",
    "    elif species in cryptodb:\n",
    "    # elif species.startswith('C') and species is not \"CveliaCCMP2878\" and species is not 'CsuisWienI' and \\\n",
    "#         species is not 'CcayetanensisCHN_HEN01' and species is not 'CfelisWinnie' \\\n",
    "#         and species is not 'CfasciculataCfCl':\n",
    "        # CveliaCCMP2878_May20.tsv is Chromera\n",
    "        # CsuisWienI_May20.tsv is Cystoisospora (Apicomplexan)\n",
    "        # CcayetanensisCHN_HEN01_May20.tsv is Cyclospora (Apicomplexan)\n",
    "        # CfelisWinnie_May20.tsv is Cytauxzoon(Apicomplexan)\n",
    "        # CfasciculataCfCl_May20 is kinetoplastid \n",
    "        model_compartments = [\"_c\",\"_e\",\"_m\"]\n",
    "    \n",
    "    # Toxoplasma = cytosol, extracellular, mitochondrdia, apicoplast\n",
    "    elif species in toxodb:\n",
    "#     elif species.startswith('Tgondii'):\n",
    "        model_compartments = [\"_c\",\"_e\",\"_ap\",\"_m\"]\n",
    "        \n",
    "    # Giardia, Entamoeba = cytosol, extracellular  \n",
    "    elif species in giardiadb or species in amoebadb:\n",
    "#     elif (species.startswith('G') or species.startswith('Edis') or species.startswith('Ehis') or \\\n",
    "#     species.startswith('Einvad') or species.startswith('Emoshk') or species.startswith('Enutt')) and \\\n",
    "#     species is not 'GniphandrodesUnknown_May20.tsv':\n",
    "        # GniphandrodesUnknown_May20.tsv is Gregarina (apicomplexan)\n",
    "        model_compartments = [\"_c\",\"_e\"]\n",
    "   \n",
    "    else:\n",
    "        model_compartments = [\"_c\",\"_e\"]\n",
    "    \n",
    "    compartment_dictionary[species] = model_compartments\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "columns = ['species','reactions_removed1','mets_removed1','reactions_removed2','mets_removed2','reactions_added', 'mets_added','gene_change']\n",
    "modifications = pd.DataFrame(index = new_model_dict.keys(), columns=columns)\n",
    "inappropriate_compartments_that_remain = dict()\n",
    "transport_for_inappropariate_compartment_dict = dict()\n",
    "\n",
    "for species, model in new_model_dict.items():\n",
    "    \n",
    "    print(species)\n",
    "    print('finding good or bad reactions')\n",
    "    compartment = compartment_dictionary[species]\n",
    "    not_compartments = compartment_options - set(compartment)\n",
    "\n",
    "    # get reactions that use/make at least one metabolite that is in an inappropariate compartment\n",
    "    good_rxns = list()\n",
    "    bad_rxns = list()\n",
    "    not_compartments = [x+' ' for x in not_compartments]\n",
    "    for rxn_object in model.reactions: # if a reaction does not contain any bad compartments\n",
    "        rxn_bad_counter = 0\n",
    "        for x in not_compartments:\n",
    "            if x in rxn_object.reaction or rxn_object.reaction.endswith(x[:-1]):\n",
    "                rxn_bad_counter = rxn_bad_counter + 1\n",
    "        if rxn_bad_counter == 0:\n",
    "            good_rxns.append(rxn_object.id)\n",
    "        else:\n",
    "            bad_rxns.append(rxn_object.id)\n",
    "     \n",
    "    print('found good or bad reactions, now doing things')       \n",
    "    bad_rxns_keep_rewrite = list()\n",
    "    add_reaction = list()\n",
    "    remove_rxn = list()\n",
    "    for rxn_id in bad_rxns: \n",
    "        if len(universal_dict_with_alts[rxn_id]['alternative_reactions']) == 0:\n",
    "            bad_rxns_keep_rewrite.append(rxn_id) # no alternative, keep reaction - will have to change via strings\n",
    "        else:\n",
    "            alt_rxns = universal_dict_with_alts[rxn_id]['alternative_reactions']\n",
    "            keep_og = 0\n",
    "            for alt_rxn_1, locations in alt_rxns.items():\n",
    "                keep_alt = 0\n",
    "                for loc in locations:\n",
    "                    if loc in compartment: keep_alt = keep_alt \n",
    "                    else: keep_alt = keep_alt + 1 \n",
    "                if keep_alt == 0:\n",
    "                    keep_og = 1\n",
    "                    add_reaction.append(alt_rxn_1)\n",
    "                else:  \n",
    "                    keep_og = keep_og\n",
    "            if keep_og == 0:\n",
    "                bad_rxns_keep_rewrite.append(rxn_id) # no usable alternative - will have to change via strings\n",
    "            else:\n",
    "                remove_rxn.append(rxn_id)\n",
    "    add_reaction = list(set(add_reaction))\n",
    "\n",
    "    if (len((bad_rxns)) == (len((remove_rxn)) + len((bad_rxns_keep_rewrite)))):\n",
    "        print('bad reactions are split into remove reactions and bad reactions to rewrite - math is good')\n",
    "\n",
    "    print('no. reactions removed')\n",
    "    print(len(remove_rxn))\n",
    "    print('no. reactions to add')\n",
    "    print(len(add_reaction))\n",
    "    \n",
    "    # remove reactions\n",
    "    x = len(model.reactions)\n",
    "    y = len(model.metabolites)\n",
    "    model.remove_reactions(remove_rxn)\n",
    "    model.repair()\n",
    "    if len(remove_rxn) != (x - len(model.reactions)):\n",
    "        print('reaction not removed properly')\n",
    "    x1 = x - len(model.reactions)\n",
    "    y1 = y - len(model.metabolites)\n",
    "    \n",
    "    # save this number\n",
    "    inappropriate_compartments_that_remain[species] = (len(bad_rxns_keep_rewrite)/len(model.reactions))*100\n",
    "    print((len(bad_rxns_keep_rewrite)/len(model.reactions))*100)\n",
    "\n",
    "    modifications.species.loc[species] = species\n",
    "    modifications.reactions_removed1.loc[species] = x1\n",
    "    #     modifications.mets_removed1.loc[species] = y1\n",
    "\n",
    "    for rxn_id in add_reaction: #there are ids in add_reaction that are in the model already\n",
    "        rxn = universal_model.reactions.get_by_id(rxn_id).copy()\n",
    "        for met in rxn.metabolites:\n",
    "            if met.id not in [m.id for m in model.metabolites]:\n",
    "                model.add_metabolites(met.copy())\n",
    "    rxns_to_add_list = [universal_model.reactions.get_by_id(x).copy() for x in add_reaction if x not in [r.id for r in model.reactions]]\n",
    "    # if reaction is already there, it is because the reaction was in multiple compartments\n",
    "    # print([rxn.id for rxn in rxns_to_add_list if rxn.id not in add_reaction])\n",
    "    model.add_reactions(rxns_to_add_list)\n",
    "    modifications.reactions_added.loc[species] = len(model.reactions) - x1 # CHECK\n",
    "\n",
    "#     if '_x' in ([x.id[-2:] for x in model.metabolites]): print('ERROR, UNACCEPTABLE COMPARTMENTS, should be some here')\n",
    "#     print('the right number of reactions are being added and removed')\n",
    "\n",
    "    for rxn in model.reactions:\n",
    "        if rxn.lower_bound == 0 and rxn.upper_bound == 0:\n",
    "            print(rxn.id + ' has bounds == 0 in '+key)\n",
    "            rxn.lower_bound = -1000.\n",
    "            rxn.upper_bound = 1000.\n",
    "            # NOTHING SHOULD PRINT - this was a problem in CarveMe\n",
    "\n",
    "    new_model_dict[species] = model\n",
    "    # cobra.io.save_json_model(model, \"TEST_DIY5_\"+species+\"_TEST.json\")\n",
    "\n",
    "    fix_these_reactions_list = list(set([model.reactions.get_by_id(x) for x in bad_rxns_keep_rewrite]))\n",
    "\n",
    "    reactions_added = list()\n",
    "    transport_for_inappropariate_compartment = list()\n",
    "\n",
    "    og = len(model.reactions)\n",
    "    og_mets= len(model.metabolites)\n",
    "    \n",
    "    print('starting to move reactions to the right compartment, if this function isnt yet in BiGG')\n",
    "    for rxn in fix_these_reactions_list:\n",
    "        \n",
    "        if [hf.met_ids_without_comp(model,x.id) for x in rxn.reactants] == [hf.met_ids_without_comp(model,x.id) for x in rxn.products]:\n",
    "            # remove things like x_p + y_p => x_e + y_e\n",
    "            transport_for_inappropariate_compartment.append(rxn.id)\n",
    "            new_rxn = list() # double check\n",
    "        else:\n",
    "\n",
    "            new_rxn = Reaction()\n",
    "            met_dict = dict()\n",
    "\n",
    "            for met in rxn.metabolites:\n",
    "\n",
    "                if hf.get_comp(model,met.id) == '_p': # move periplasmic metabolites to extracellular instead of cytosol\n",
    "                    if hf.met_ids_without_comp(model,met.id)+'_e' not in [x.id for x in model.metabolites]:\n",
    "                        met2 = met.copy()\n",
    "                        met2.id = hf.met_ids_without_comp(model,met.id)+'_e'\n",
    "                        met_dict[met2] = rxn.metabolites[met]\n",
    "                        model.add_metabolites(met2) # []\n",
    "                    else:\n",
    "                        met2 = model.metabolites.get_by_id(hf.met_ids_without_comp(model,met.id)+'_e')\n",
    "                        met_dict[met2] = rxn.metabolites[met]\n",
    "                else: # non periplasmic metabolite\n",
    "                    if hf.met_ids_without_comp(model,met.id)+'_c' not in [x.id for x in model.metabolites]:\n",
    "                        met2 = met.copy()\n",
    "                        met2.id = hf.met_ids_without_comp(model,met.id)+'_c'\n",
    "                        met_dict[met2] = rxn.metabolites[met]\n",
    "                        model.add_metabolites(met2) # []\n",
    "                    else:\n",
    "                        met2 = model.metabolites.get_by_id(hf.met_ids_without_comp(model,met.id)+'_c')\n",
    "                        met_dict[met2] = rxn.metabolites[met]\n",
    "\n",
    "        # fix reaction variables\n",
    "        if new_rxn:\n",
    "            new_rxn.add_metabolites(met_dict)\n",
    "            new_rxn.name = rxn.name\n",
    "            new_rxn.id = rxn.id+'c'\n",
    "            new_rxn.lower_bound = rxn.lower_bound\n",
    "            new_rxn.upper_bound = rxn.upper_bound\n",
    "            new_rxn.gene_reaction_rule = rxn.gene_reaction_rule\n",
    "            model.add_reactions([new_rxn])\n",
    "            reactions_added.append(new_rxn.id)\n",
    "\n",
    "        model.remove_reactions([rxn])\n",
    "        \n",
    "    model.repair()\n",
    "    print('finished moving reactions to the right compartment')\n",
    "\n",
    "    print('reactions added overall')\n",
    "    print(len(model.reactions) - og)\n",
    "    # print('mets added')\n",
    "    # print(len(model.metabolites) - og_mets)\n",
    "    transport_for_inappropariate_compartment_dict[species] = list(set(transport_for_inappropariate_compartment))\n",
    "\n",
    "    new_model_dict[species] = model\n",
    "    # cobra.io.save_json_model(model, \"DIY6_\"+species+\".json\")\n",
    "    l2 = list()\n",
    "    for rxn in model.reactions:\n",
    "        for suffix in [m.id[-2:] for m in rxn.metabolites]:\n",
    "            l2.append(suffix)\n",
    "    print('compartments')\n",
    "    print(set(l2))\n",
    "\n",
    "# modifications.to_csv('model_modifications_oct4.csv')\n",
    "# pd.DataFrame.from_dict(inappropriate_compartments_that_remain, orient=\"index\").to_csv(\"percent_reactions_in_wrong_compartment_oct4.csv\")\n",
    "      \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# future thought:\n",
    "# what to do for reactions like this:\n",
    "#     model_dict['Vculicisfloridensis_May20.tsv'].reactions.get_by_id('O16A4COLIPAabctex')\n",
    "# transport from extracellular to periplasm\n",
    "# what to do with reactions like this:\n",
    "#'atp_c + h2o_c + o16a4colipa_p --> adp_c + h_c + o16a4colipa_e + pi_c'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = list()\n",
    "for key in new_model_dict.keys():\n",
    "    for x in new_model_dict[key].reactions:\n",
    "        for met in x.metabolites:\n",
    "            l.append(met.id[-2:])\n",
    "set(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for species in new_model_dict.keys():\n",
    "    print(species)\n",
    "    list_om= list()\n",
    "    list_om2= list()\n",
    "    for x in new_model_dict[species].reactions:\n",
    "        for m in x.metabolites:\n",
    "            list_om.append(m.id[-2:])\n",
    "    for m in new_model_dict[species].metabolites:\n",
    "        list_om2.append(m.id[-2:])\n",
    "    set(list_om)\n",
    "    print(set(list_om))\n",
    "    print(set(list_om2))\n",
    "    \n",
    "## use my cobra.manipulation.delete.prune_unused_metabolites(model_dict[species])\n",
    "# do above again"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
