{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13.4\n"
     ]
    }
   ],
   "source": [
    "import cobra\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from cobra import Model, Reaction, Metabolite\n",
    "import subprocess\n",
    "print (cobra.__version__) # Use Devel branch\n",
    "\n",
    "#metabolic_tasks_from_spreadsheet\n",
    "#gene_lists_to_sparse_matrix\n",
    "\n",
    "path = \"/Users/maureencarey/local_documents/work/comparative_parasite_models/paradigm\"\n",
    "data_path = \"/Users/maureencarey/local_documents/work/comparative_parasite_models/paradigm_preOct2018/data\"\n",
    "\n",
    "os.chdir(data_path)\n",
    "universal_model = cobra.io.load_json_model('universal_model_may2018.json')\n",
    "    \n",
    "for rxn in universal_model.reactions:\n",
    "    if rxn.id.startswith('EX_'):\n",
    "        rxn.lower_bound = -1000.\n",
    "        rxn.upper_bound = 1000.\n",
    "        \n",
    "for met in universal_model.metabolites:\n",
    "    if met.id.endswith('_e'):\n",
    "        if 'EX_'+met.id not in universal_model.reactions:\n",
    "            universal_model.add_boundary(met, type = 'exchange')\n",
    "\n",
    "for rxn in [r for r in universal_model.reactions if r.id.lower().startswith('biomass')]:\n",
    "    rxn.remove_from_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preliminary curation (iPfal17)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS CELL ASSUMES preliminary_iPfal17_curation.ipynb WAS ALREADY RUN\n",
    "\n",
    "os.chdir(data_path+'/other_models')\n",
    "iPfal17 = cobra.io.read_sbml_model(\"iPfal17.xml\") # RUN iPfal17_curation_part1.ipyb\n",
    "iPfal18 = cobra.io.read_sbml_model(\"iPfal18_pregapfilling.xml\")\n",
    "iPfal17.solver = 'gurobi'\n",
    "iPfal18.solver = 'gurobi'\n",
    "\n",
    "pf_biomass = iPfal18.reactions.get_by_id('biomass').copy()\n",
    "pf_biomass_mets = [x.copy() for x in iPfal18.reactions.get_by_id('biomass').metabolites]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN biomass_comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# add curated reactions to reaction bag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN build_universal_reaction_bag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# download genomes\n",
    "# in R\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map BiGG IDs a la Carve Me but de novo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build models on rivanna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SLURM SCRIPT NAME\n",
    "# build_de_novo_models.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.chdir(data_path+'/diy6_output')\n",
    "# # add _Jul2018_BiGG to DIY6_LmajorSD75\n",
    "# model_dict = dict()\n",
    "# skip = list()\n",
    "# for filename in glob.glob(os.path.join(data_path+'/diy6_output', '*.json')):\n",
    "#     if 'Jul2018_BiGG' in filename:\n",
    "#         key = filename.split('/')[len(filename.split('/'))-1]\n",
    "#         key = key[:-18] # get rid of _Jul2018_BiGG.json\n",
    "#         if key.startswith('DIY6_'):\n",
    "#             key = key[5:]\n",
    "#         model_dict[key] = cobra.io.load_json_model(filename)\n",
    "#         model_dict[key].solver = 'gurobi'\n",
    "# #     elif 'LmajorSD75' in filename:\n",
    "# #         key = filename.split('/')[len(filename.split('/'))-1]\n",
    "# #         key = key[:-5] # get rid of .json\n",
    "# #         if key.startswith('DIY6_'):\n",
    "# #             key = key[5:]\n",
    "# #         model_dict[key] = cobra.io.load_json_model(filename)\n",
    "# #         model_dict[key].solver = 'gurobi'\n",
    "#     else:\n",
    "#         skip.append(filename)\n",
    "# len(model_dict.keys())\n",
    "# model_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# add generic biomass function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# orthology transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['PblacklockiG01', 'PfragileNilgiri', 'Pfalciparum3D7', 'PinuiSanAntonio1', 'PbillcollinsiG01', 'PvivaxP01', 'PcynomolgiB', 'Pyoeliiyoelii17X', 'PbergheiANKA', 'PgaboniG01', 'Pyoeliiyoelii17XNL', 'PadleriG01', 'PpraefalciparumG01', 'PreichenowiCDC', 'PyoeliiyoeliiYM', 'PrelictumSGS1-like', 'Pgallinaceum8A', 'PmalariaeUG01', 'PcynomolgiM', 'PfalciparumIT', 'Pvinckeivinckeivinckei', 'PcoatneyiHackeri', 'PknowlesiH', 'PvinckeipetteriCR', 'PreichenowiG01', 'PovalecurtisiGH01', 'PvivaxSal1', 'PgaboniSY75', 'PknowlesiMalayanPk1A', 'Pchabaudichabaudi'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pf_model_dict = dict()\n",
    "os.chdir(data_path+\"/diy_ortho_output\")\n",
    "for filename in glob.glob(os.path.join(data_path+\"/diy_ortho_output\", '*.json')):\n",
    "    key = filename.split('/')[len(filename.split('/'))-1]\n",
    "    key = key[:-5]\n",
    "    key = key[10:]\n",
    "    pf_model_dict[key] = cobra.io.load_json_model(filename) \n",
    "pf_model_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_model = pf_model_dict['PvivaxSal1']\n",
    "\n",
    "# atp = test_model.metabolites.get_by_id('atp_c')\n",
    "# if 'EX_atp_c' not in [r.id for r in test_model.reactions]:\n",
    "#     atp_production = test_model.add_boundary(atp, type=\"exchange\", reaction_id='atp_production')\n",
    "#     test_model.objective = atp_production\n",
    "# else:\n",
    "#     print('already there')\n",
    "#     test_model.objective = test_model.reactions.get_by_id('EX_atp_c')\n",
    "\n",
    "# test_model.solver = 'gurobi'\n",
    "# test_model.solver.configuration.timeout = 3600 #360 worked for one iteration, not for 10\n",
    "# if test_model.slim_optimize() <0.1:\n",
    "#     result2 = gapfill2(test_model,universal= universal_model, \n",
    "#                       demand_reactions = False, exchange_reactions = True, iterations=10)\n",
    "# else:\n",
    "#     result2 = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# curate to metabolic tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# curation_USE.xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [x.reaction for x in pf_curated.metabolites.get_by_id('dxyl5p_ap').reactions]\n",
    "# # pf_curated.metabolites.thmpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['model','metabolite','metabolite group','can scavange?','synthesize?','essential?']\n",
    "auxotrophy_table = pd.DataFrame(columns=columns)\n",
    "\n",
    "met_group_dict = {\n",
    "    'glc__D':'carbon source',\n",
    "    'fru':'carbon source',\n",
    "    'cit':'carbon source',\n",
    "    'glyc':'carbon source',\n",
    "    'orn':'carbon source',\n",
    "    'arg__L':'carbon source, amino acid',\n",
    "    'ala__L':'carbon source, amino acid',\n",
    "    'his__L':'carbon source, amino acid',\n",
    "    'lys__L':'carbon source, amino acid',\n",
    "    'asp__L':'carbon source, amino acid',\n",
    "    'gln__L':'carbon source, amino acid',\n",
    "    'glu__L':'carbon source, amino acid',\n",
    "    'ser__L':'carbon source, amino acid',\n",
    "    'thr__L':'carbon source, amino acid',\n",
    "    'asn__L':'carbon source, amino acid',\n",
    "    'cys__L':'carbon source, amino acid',\n",
    "    'gly__L':'carbon source, amino acid',\n",
    "    'pro__L':'carbon source, amino acid',\n",
    "    'val__L':'carbon source, amino acid',\n",
    "    'ile__L':'carbon source, amino acid',\n",
    "    'leu__L':'carbon source, amino acid',\n",
    "    'met__L':'carbon source, amino acid',\n",
    "    'phe__L':'carbon source, amino acid',\n",
    "    'tyr__L':'carbon source, amino acid',\n",
    "    'trp__L':'carbon source, amino acid',\n",
    "    'thym':'nucleotide, pyrimidine',\n",
    "    'csn':'nucleotide, pyrimidine',\n",
    "    'ura':'nucleotide, pyrimidine',\n",
    "    'ade':'nucleotide, purines',\n",
    "    'gua':'nucleotide, purines',\n",
    "    'hxan':'nucleotide, purines',\n",
    "    'xan':'nucleotide, purines',\n",
    "    \n",
    "} \n",
    "\n",
    "met_long_name_dict = {\n",
    "    'glc__D':'glucose',\n",
    "    'fru': 'fructose',\n",
    "    'cit':'citric acid'\n",
    "    'glyc':'glycerol',\n",
    "    'orn':'ornithine'\n",
    "    'ala__L':'alanine',\n",
    "    'arg__L':'arginine',\n",
    "    'his__L':'histidine',\n",
    "    'lys__L':'lysine',\n",
    "    'asp__L':'aspartate',\n",
    "    'gln__L':'glutamine',\n",
    "    'glu__L':'glutamate',\n",
    "    'ser__L':'serine',\n",
    "    'thr__L':'threonine',\n",
    "    'asn__L':'asparagine',\n",
    "    'cys__L':'cysteine',\n",
    "    'gly__L':'glycine',\n",
    "    'pro__L':'proline',\n",
    "    'val__L':'valine',\n",
    "    'ile__L':'isoleucine',\n",
    "    'leu__L':'leucine',\n",
    "    'met__L':'methionine',\n",
    "    'phe__L':'phenylalanine',\n",
    "    'tyr__L':'tyrosine',\n",
    "    'trp__L':'tryptophane',\n",
    "    'thym':'thymine',\n",
    "    'csn':'cytosine',\n",
    "    'ura':'uracil',\n",
    "    'ade':'adenine',\n",
    "    'gua':'guanine',\n",
    "    'hxan':'hypoxanthine',\n",
    "    'xan':'xanthine'\n",
    "}\n",
    "\n",
    "for key, model in models_dict.items():\n",
    "    for met in met_group_dict.keys():\n",
    "        \n",
    "        met_group = met_group_dict[met]\n",
    "        met_long_name = met_long_name_dict[met]\n",
    "        \n",
    "        result0 = \n",
    "        result1 = \n",
    "        result2 = \n",
    "        \n",
    "        auxotrophy_table = auxotrophy_table.append({'model':key, \n",
    "                                                    'metabolite':met_long_name,\n",
    "                                                    'metabolite group': met_group,\n",
    "                                                    'can scavange?':result0,\n",
    "                                                    'synthesize?':result1,\n",
    "                                                    'essential?':result2}, \n",
    "                                                   ignore_index = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLASMODIUM MODELS DONT HAVE APPROPRIATE BIOMASS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# phe__L\n",
    "# add exchange\n",
    "# produce\n",
    "# solution\n",
    "# ['EX_phephe_e', 'PHEPHEr', 'ACChex', 'PHEPHEt']\n",
    "# how to limit exchange reactions - specifically small peptides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
